**A list with some most recent Open Source LLM Models with their license** (e.g. comercial use) --> Contribute more if you know!

_Note: Verify this information before using._

## 1. LLaMA 3.1
* Developer: Meta
* Parameters: 8B, 70B, 405B
* Release Date: July 23, 2024
* License: Open for commercial use with attribution.
* Details: This model features significant improvements, including a larger parameter count and expanded context length (up to 128,000 tokens). It supports multiple languages and is designed for various natural language processing tasks.

## 2. Gemma 2
* Developer: Nomic AI
* Parameters: 9B or 27B
* License: Check specifics; generally permissive.
* Details: Supports a context length of 8,192 tokens. Trained on approximately 13 trillion tokens for the 27B version and 8 trillion for the 9B version, utilizing a mix of web data, code, and mathematical content. Gemma 2 shows competitive performance against larger models, often outperforming them in specific benchmarks.

## 3. Falcon 180B
* Developer: Technology Innovation Institute
* Parameters: 180B
* License: Open-source; suitable for commercial use.
* Details: Falcon models are known for their performance across various AI benchmarks and applications, including content generation and sentiment analysis.

## 4. Mistral 7B
* Developer: Mistral AI
* Parameters: 7.3B
* Release Date: September 27, 2023
* License: Apache 2.0; unrestricted for commercial use.
* Details: Outperforms many other models in terms of efficiency and accuracy across various metrics.

## 5. Dolly 2.0
* Developer: Databricks
* License: Commercial use allowed.
* Details: Designed for instruction-following tasks, available for commercial applications with attribution.

## 6. BLOOM
* Developer: BigScience
* Parameters: 176B
* License: Open access for commercial use with attribution.
* Details: A powerful model that supports multiple languages and programming languages, emphasizing transparency and accessibility.

## 7. FLAN-T5
* Developer: Google
* Parameters: Ranges from small (80M) to large (11B)
* License: Generally permissive (Apache 2.0).
* Details: Optimized for few-shot learning tasks and multilingual support, available for commercial use.

## 8. Command R+
* Developer: Cohere
* License: Check specifics; generally permissive.
* Details: A recent addition focused on retrieval-augmented generation tasks.

## 9 DBRX
* Developer: Databricks and Mosaic
* Parameters: 132B
* License: Check specifics; generally permissive.
* Details: Known for its powerful performance across various benchmarks.

## 10. XGen-7B
  * Developer: Salesforce
  * Parameters: 7B
  * Release Date: July 2023
  * License: Available for commercial and research purposes (with some variants under non-commercial licenses).
  * Details: Designed to support longer context windows (up to 8K), making it suitable for tasks requiring extensive input.

## 11. GPT-NeoX and GPT-J
* Developer: EleutherAI
* Parameters: GPT-NeoX (20B), GPT-J (6B)
* License: Open-source; suitable for commercial use.
* Details: These models provide solid performance across various tasks despite having fewer parameters compared to newer models.

## Others:
* **12. OLMo** (Open Language Model)
  - Developed by the Allen Institute for AI (AI2), OLMo focuses on transparency and reproducibility in NLP tasks.
*  **13. h2oGPT**
  - Developed by H2O.ai, this model ranges from 12 billion to 20 billion parameters and emphasizes transparency and interpretability.
 *  **14.  Stable LM**
  - Developed by Stability AI, this model aims to provide a balance between size and performance while being open-source.
